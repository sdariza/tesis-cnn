{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPBQkw+sWbva5e9GElGpsy+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdariza/tesis-cnn/blob/master/Plan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install netCDF4\n",
        "!pip install basemap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_8UKPmOfu6Ns",
        "outputId": "7236ef4d-e024-4ada-efc1-2367b8d2e05b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.2.0-py3-none-any.whl (390 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.6.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 cmaes-0.9.1 colorlog-6.7.0 optuna-3.2.0\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2023.5.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.22.4)\n",
            "Installing collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.2 netCDF4-1.6.4\n",
            "Collecting basemap\n",
            "  Downloading basemap-1.3.7-cp310-cp310-manylinux1_x86_64.whl (860 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m860.6/860.6 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting basemap-data<1.4,>=1.3.2 (from basemap)\n",
            "  Downloading basemap_data-1.3.2-py2.py3-none-any.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyshp<2.4,>=1.2 (from basemap)\n",
            "  Downloading pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib<3.8,>=1.5 in /usr/local/lib/python3.10/dist-packages (from basemap) (3.7.1)\n",
            "Collecting pyproj<3.6.0,>=1.9.3 (from basemap)\n",
            "  Downloading pyproj-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.25,>=1.22 in /usr/local/lib/python3.10/dist-packages (from basemap) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.8,>=1.5->basemap) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj<3.6.0,>=1.9.3->basemap) (2023.5.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<3.8,>=1.5->basemap) (1.16.0)\n",
            "Installing collected packages: pyshp, pyproj, basemap-data, basemap\n",
            "  Attempting uninstall: pyproj\n",
            "    Found existing installation: pyproj 3.6.0\n",
            "    Uninstalling pyproj-3.6.0:\n",
            "      Successfully uninstalled pyproj-3.6.0\n",
            "Successfully installed basemap-1.3.7 basemap-data-1.3.2 pyproj-3.5.0 pyshp-2.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import optuna\n",
        "import netCDF4 as nc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "BATCHSIZE = 12\n",
        "EPOCHS=100"
      ],
      "metadata": {
        "id": "mplrCdBMsnNy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(trial):\n",
        "  kernel_sizes = [(2,2),(2,3),(3,2),(3,3),(2,4),(4,2),(3,4),(4,3),(4,4)]\n",
        "  kz_selected = trial.suggest_categorical(\"kernel_size\", kernel_sizes)\n",
        "  alphas = [.5, .7, .9]\n",
        "  alpha_selected = trial.suggest_categorical(\"alpha\", alphas)\n",
        "  model = tf.keras.models.Sequential(name=f'CNN-Weather-Forecasting-Optimizing-Parameters')\n",
        "  model.add(tf.keras.layers.Input(shape=(181,360,1), name='input_layer'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=kz_selected, padding='same', name='conv2D_1'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_1'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=kz_selected, padding='same', name='conv2D_2'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_2'))\n",
        "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),padding='same', name='AvP_1'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=kz_selected, padding='same', name='conv2D_3'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_3'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=kz_selected, padding='same', name='conv2D_4'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_4'))\n",
        "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),padding='same', name='AvP_2'))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=kz_selected, padding='same', name='conv2D_5'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_5'))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=kz_selected, padding='same', name='conv2DT_1'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_6'))\n",
        "  model.add(tf.keras.layers.UpSampling2D(size=(2,2), name='UpS2D_1'))\n",
        "  model.add(tf.keras.layers.Cropping2D(cropping=((1,0),(0,0)), name='Cropping_1'))\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=kz_selected, padding='same', name='conv2DT_2'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_7'))\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=kz_selected, padding='same', name='conv2DT_3'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_8'))\n",
        "  model.add(tf.keras.layers.UpSampling2D(size=(2,2), name='UpS2D_2'))\n",
        "  model.add(tf.keras.layers.Cropping2D(cropping=((1,0),(0,0)), name='Cropping_2'))\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=kz_selected, padding='same', name='conv2DT_4'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_9'))\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=kz_selected, padding='same', name='output'))\n",
        "  model.add(tf.keras.layers.LeakyReLU(alpha=alpha_selected, name='act_10'))\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "rSXNokGKrWPB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_optimizer(trial):\n",
        "  kwargs = {}\n",
        "  kwargs[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
        "  optimizer = getattr(tf.optimizers, 'Adam')(**kwargs)\n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "rn_8URA663rw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OPvYuNudNC7",
        "outputId": "93ce8289-a925-4afd-aba6-d87e165aac36"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_temp = nc.Dataset('/content/drive/MyDrive/research/nc-files/t0.nc')\n",
        "X = X_temp.variables['t'][:].data - 273.15\n",
        "Y_temp = nc.Dataset('/content/drive/MyDrive/research/nc-files/t6.nc')\n",
        "Y = Y_temp.variables['t'][:].data - 273.15"
      ],
      "metadata": {
        "id": "lue7UWw5gNSm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_temp.close()\n",
        "Y_temp.close()"
      ],
      "metadata": {
        "id": "x6G3nG5-xQya"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    # Split the data into training, validation, and test sets\n",
        "    split_ratio_train = 0.8\n",
        "    split_ratio_val = 0.2\n",
        "    num_samples = len(X)\n",
        "    num_train = int(split_ratio_train * num_samples)\n",
        "    num_val = int(split_ratio_val * num_samples)\n",
        "    train_data = X[:num_train]\n",
        "    val_data = X[num_train:num_train+num_val]\n",
        "    train_labels = Y[:num_train]\n",
        "    val_labels = Y[num_train:num_train+num_val]\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(tensors=(train_data, train_labels))\n",
        "    train_ds = train_ds.shuffle(60000).batch(BATCHSIZE)\n",
        "\n",
        "    valid_ds = tf.data.Dataset.from_tensor_slices(tensors=(val_data, val_labels))\n",
        "    valid_ds = valid_ds.shuffle(10000).batch(BATCHSIZE)\n",
        "\n",
        "    return train_ds, valid_ds"
      ],
      "metadata": {
        "id": "--G3LPN-Fpuc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_metric(history, params, _trial_id):\n",
        "    # Obtener las métricas del entrenamiento y la validación\n",
        "    train_loss = history.history['loss']\n",
        "    train_mae = history.history['mean_absolute_error']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_mae = history.history['val_mean_absolute_error']\n",
        "\n",
        "    # Graficar las métricas\n",
        "    epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    kz, op, lr = params['kernel_size'], params['optimizer'], params['learning_rate']\n",
        "    selected_arch = params['arch']\n",
        "    plt.suptitle(f'trialId:{_trial_id} arch:{selected_arch} kz:{kz} op:{op}, lr:{lr}')\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, np.log(train_loss), label='Training Loss')\n",
        "    plt.plot(epochs, np.log(val_loss), label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('$log(loss)$')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, np.log(train_mae), label='Training MAE')\n",
        "    plt.plot(epochs, np.log(val_mae), label='Validation MAE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('$log(MAE)$')\n",
        "    plt.title(f'Training and Validation MAE')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'optimizePlots/trial{_trial_id}arch{selected_arch}.png')"
      ],
      "metadata": {
        "id": "EDj33pePrkRE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    train_ds, valid_ds = get_data()\n",
        "\n",
        "    model = create_model(trial)\n",
        "    optimizer = create_optimizer(trial)\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10, mode='auto', verbose=1)\n",
        "    model.compile(optimizer=optimizer,loss=tf.keras.losses.MeanSquaredError(), metrics=tf.keras.losses.MeanAbsoluteError())\n",
        "    history = model.fit(train_ds, validation_data=valid_ds, epochs=EPOCHS, callbacks=[early_stop], verbose=1)\n",
        "\n",
        "    plot_loss_metric(history,trial.__dict__['_cached_frozen_trial'].params,trial.__dict__['_trial_id'])\n",
        "\n",
        "    mae = model.evaluate(valid_ds)[1]\n",
        "\n",
        "    return mae"
      ],
      "metadata": {
        "id": "coNc68Fkr2Ve"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkJ0YXTOsDbc",
        "outputId": "f7bb6845-7487-4b09-c770-e499890fb9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-07-03 03:36:13,006] A new study created in memory with name: no-name-800c5b3f-90e7-4d8e-a755-65df171b6901\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2, 2) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2, 3) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (3, 2) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (3, 3) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (2, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (4, 2) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (3, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (4, 3) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (4, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"CNN-Weather-Forecasting-Optimizing-Parameters\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2D_1 (Conv2D)           (None, 181, 360, 32)      288       \n",
            "                                                                 \n",
            " act_1 (LeakyReLU)           (None, 181, 360, 32)      0         \n",
            "                                                                 \n",
            " conv2D_2 (Conv2D)           (None, 181, 360, 32)      8224      \n",
            "                                                                 \n",
            " act_2 (LeakyReLU)           (None, 181, 360, 32)      0         \n",
            "                                                                 \n",
            " AvP_1 (AveragePooling2D)    (None, 91, 180, 32)       0         \n",
            "                                                                 \n",
            " conv2D_3 (Conv2D)           (None, 91, 180, 64)       16448     \n",
            "                                                                 \n",
            " act_3 (LeakyReLU)           (None, 91, 180, 64)       0         \n",
            "                                                                 \n",
            " conv2D_4 (Conv2D)           (None, 91, 180, 64)       32832     \n",
            "                                                                 \n",
            " act_4 (LeakyReLU)           (None, 91, 180, 64)       0         \n",
            "                                                                 \n",
            " AvP_2 (AveragePooling2D)    (None, 46, 90, 64)        0         \n",
            "                                                                 \n",
            " conv2D_5 (Conv2D)           (None, 46, 90, 128)       65664     \n",
            "                                                                 \n",
            " act_5 (LeakyReLU)           (None, 46, 90, 128)       0         \n",
            "                                                                 \n",
            " conv2DT_1 (Conv2DTranspose)  (None, 46, 90, 64)       65600     \n",
            "                                                                 \n",
            " act_6 (LeakyReLU)           (None, 46, 90, 64)        0         \n",
            "                                                                 \n",
            " UpS2D_1 (UpSampling2D)      (None, 92, 180, 64)       0         \n",
            "                                                                 \n",
            " Cropping_1 (Cropping2D)     (None, 91, 180, 64)       0         \n",
            "                                                                 \n",
            " conv2DT_2 (Conv2DTranspose)  (None, 91, 180, 64)      32832     \n",
            "                                                                 \n",
            " act_7 (LeakyReLU)           (None, 91, 180, 64)       0         \n",
            "                                                                 \n",
            " conv2DT_3 (Conv2DTranspose)  (None, 91, 180, 32)      16416     \n",
            "                                                                 \n",
            " act_8 (LeakyReLU)           (None, 91, 180, 32)       0         \n",
            "                                                                 \n",
            " UpS2D_2 (UpSampling2D)      (None, 182, 360, 32)      0         \n",
            "                                                                 \n",
            " Cropping_2 (Cropping2D)     (None, 181, 360, 32)      0         \n",
            "                                                                 \n",
            " conv2DT_4 (Conv2DTranspose)  (None, 181, 360, 32)     8224      \n",
            "                                                                 \n",
            " act_9 (LeakyReLU)           (None, 181, 360, 32)      0         \n",
            "                                                                 \n",
            " output (Conv2DTranspose)    (None, 181, 360, 1)       257       \n",
            "                                                                 \n",
            " act_10 (LeakyReLU)          (None, 181, 360, 1)       0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246,785\n",
            "Trainable params: 246,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "175/175 [==============================] - 43s 162ms/step - loss: 23127.8809 - mean_absolute_error: 44.0176 - val_loss: 35.7582 - val_mean_absolute_error: 3.6650\n",
            "Epoch 2/100\n",
            "175/175 [==============================] - 27s 154ms/step - loss: 27.2509 - mean_absolute_error: 3.1473 - val_loss: 21.6577 - val_mean_absolute_error: 2.8205\n",
            "Epoch 3/100\n",
            "175/175 [==============================] - 28s 158ms/step - loss: 18.3532 - mean_absolute_error: 2.5837 - val_loss: 17.6766 - val_mean_absolute_error: 2.5472\n",
            "Epoch 4/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 15.9403 - mean_absolute_error: 2.4277 - val_loss: 15.7205 - val_mean_absolute_error: 2.4278\n",
            "Epoch 5/100\n",
            "175/175 [==============================] - 29s 165ms/step - loss: 14.4045 - mean_absolute_error: 2.3366 - val_loss: 14.0847 - val_mean_absolute_error: 2.3202\n",
            "Epoch 6/100\n",
            "175/175 [==============================] - 29s 162ms/step - loss: 13.0307 - mean_absolute_error: 2.2525 - val_loss: 12.5618 - val_mean_absolute_error: 2.2307\n",
            "Epoch 7/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 11.7933 - mean_absolute_error: 2.1702 - val_loss: 11.2749 - val_mean_absolute_error: 2.1426\n",
            "Epoch 8/100\n",
            "175/175 [==============================] - 29s 163ms/step - loss: 10.7498 - mean_absolute_error: 2.0936 - val_loss: 10.3210 - val_mean_absolute_error: 2.0674\n",
            "Epoch 9/100\n",
            "175/175 [==============================] - 29s 163ms/step - loss: 9.9315 - mean_absolute_error: 2.0173 - val_loss: 9.5882 - val_mean_absolute_error: 1.9811\n",
            "Epoch 10/100\n",
            "175/175 [==============================] - 29s 167ms/step - loss: 9.2875 - mean_absolute_error: 1.9460 - val_loss: 9.0269 - val_mean_absolute_error: 1.9262\n",
            "Epoch 11/100\n",
            "175/175 [==============================] - 28s 161ms/step - loss: 8.7679 - mean_absolute_error: 1.8855 - val_loss: 8.5602 - val_mean_absolute_error: 1.8710\n",
            "Epoch 12/100\n",
            "175/175 [==============================] - 29s 163ms/step - loss: 8.3437 - mean_absolute_error: 1.8350 - val_loss: 8.1674 - val_mean_absolute_error: 1.8183\n",
            "Epoch 13/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 7.9881 - mean_absolute_error: 1.7924 - val_loss: 7.8398 - val_mean_absolute_error: 1.7812\n",
            "Epoch 14/100\n",
            "175/175 [==============================] - 29s 162ms/step - loss: 7.6889 - mean_absolute_error: 1.7585 - val_loss: 7.6031 - val_mean_absolute_error: 1.7561\n",
            "Epoch 15/100\n",
            "175/175 [==============================] - 29s 166ms/step - loss: 7.4253 - mean_absolute_error: 1.7277 - val_loss: 7.3013 - val_mean_absolute_error: 1.7138\n",
            "Epoch 16/100\n",
            "175/175 [==============================] - 29s 165ms/step - loss: 7.1861 - mean_absolute_error: 1.6998 - val_loss: 7.0887 - val_mean_absolute_error: 1.6933\n",
            "Epoch 17/100\n",
            "175/175 [==============================] - 30s 170ms/step - loss: 6.9693 - mean_absolute_error: 1.6746 - val_loss: 6.8738 - val_mean_absolute_error: 1.6682\n",
            "Epoch 18/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 6.7793 - mean_absolute_error: 1.6568 - val_loss: 6.7558 - val_mean_absolute_error: 1.6762\n",
            "Epoch 19/100\n",
            "175/175 [==============================] - 30s 168ms/step - loss: 6.6093 - mean_absolute_error: 1.6406 - val_loss: 6.5021 - val_mean_absolute_error: 1.6203\n",
            "Epoch 20/100\n",
            "175/175 [==============================] - 28s 161ms/step - loss: 6.4208 - mean_absolute_error: 1.6130 - val_loss: 6.6073 - val_mean_absolute_error: 1.7115\n",
            "Epoch 21/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 6.2849 - mean_absolute_error: 1.5996 - val_loss: 6.2155 - val_mean_absolute_error: 1.5910\n",
            "Epoch 22/100\n",
            "175/175 [==============================] - 29s 167ms/step - loss: 6.1975 - mean_absolute_error: 1.5997 - val_loss: 6.0700 - val_mean_absolute_error: 1.5628\n",
            "Epoch 23/100\n",
            "175/175 [==============================] - 29s 161ms/step - loss: 6.1314 - mean_absolute_error: 1.6013 - val_loss: 6.4544 - val_mean_absolute_error: 1.7300\n",
            "Epoch 24/100\n",
            "175/175 [==============================] - 30s 168ms/step - loss: 6.0023 - mean_absolute_error: 1.5788 - val_loss: 5.8624 - val_mean_absolute_error: 1.5342\n",
            "Epoch 25/100\n",
            "175/175 [==============================] - 29s 162ms/step - loss: 6.0482 - mean_absolute_error: 1.6046 - val_loss: 5.9423 - val_mean_absolute_error: 1.5866\n",
            "Epoch 26/100\n",
            "175/175 [==============================] - 29s 163ms/step - loss: 5.8813 - mean_absolute_error: 1.5692 - val_loss: 5.7364 - val_mean_absolute_error: 1.5258\n",
            "Epoch 27/100\n",
            "175/175 [==============================] - 29s 165ms/step - loss: 5.7589 - mean_absolute_error: 1.5435 - val_loss: 5.9490 - val_mean_absolute_error: 1.6341\n",
            "Epoch 28/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 5.7370 - mean_absolute_error: 1.5492 - val_loss: 5.7423 - val_mean_absolute_error: 1.5739\n",
            "Epoch 29/100\n",
            "175/175 [==============================] - 29s 166ms/step - loss: 5.7107 - mean_absolute_error: 1.5522 - val_loss: 5.5903 - val_mean_absolute_error: 1.5219\n",
            "Epoch 30/100\n",
            "175/175 [==============================] - 29s 166ms/step - loss: 5.6524 - mean_absolute_error: 1.5443 - val_loss: 5.6003 - val_mean_absolute_error: 1.5381\n",
            "Epoch 31/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 5.5583 - mean_absolute_error: 1.5241 - val_loss: 5.3977 - val_mean_absolute_error: 1.4682\n",
            "Epoch 32/100\n",
            "175/175 [==============================] - 29s 163ms/step - loss: 5.4524 - mean_absolute_error: 1.5000 - val_loss: 5.3567 - val_mean_absolute_error: 1.4654\n",
            "Epoch 33/100\n",
            "175/175 [==============================] - 29s 165ms/step - loss: 5.4550 - mean_absolute_error: 1.5118 - val_loss: 5.2818 - val_mean_absolute_error: 1.4479\n",
            "Epoch 34/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 5.4333 - mean_absolute_error: 1.5166 - val_loss: 5.6585 - val_mean_absolute_error: 1.6022\n",
            "Epoch 35/100\n",
            "175/175 [==============================] - 30s 167ms/step - loss: 5.5024 - mean_absolute_error: 1.5427 - val_loss: 5.2991 - val_mean_absolute_error: 1.4739\n",
            "Epoch 36/100\n",
            "175/175 [==============================] - 28s 162ms/step - loss: 5.3913 - mean_absolute_error: 1.5154 - val_loss: 5.5252 - val_mean_absolute_error: 1.5737\n",
            "Epoch 37/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 5.2027 - mean_absolute_error: 1.4588 - val_loss: 5.1587 - val_mean_absolute_error: 1.4424\n",
            "Epoch 38/100\n",
            "175/175 [==============================] - 29s 163ms/step - loss: 5.2481 - mean_absolute_error: 1.4818 - val_loss: 5.0649 - val_mean_absolute_error: 1.4157\n",
            "Epoch 39/100\n",
            "175/175 [==============================] - 29s 165ms/step - loss: 5.3036 - mean_absolute_error: 1.5023 - val_loss: 5.0952 - val_mean_absolute_error: 1.4300\n",
            "Epoch 40/100\n",
            "175/175 [==============================] - 29s 163ms/step - loss: 5.1813 - mean_absolute_error: 1.4725 - val_loss: 5.0787 - val_mean_absolute_error: 1.4457\n",
            "Epoch 41/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 5.1610 - mean_absolute_error: 1.4743 - val_loss: 5.6645 - val_mean_absolute_error: 1.6453\n",
            "Epoch 42/100\n",
            "175/175 [==============================] - 29s 164ms/step - loss: 5.2114 - mean_absolute_error: 1.4956 - val_loss: 8.2546 - val_mean_absolute_error: 2.2150\n",
            "Epoch 43/100\n",
            "175/175 [==============================] - 29s 167ms/step - loss: 5.2361 - mean_absolute_error: 1.4995 - val_loss: 5.0663 - val_mean_absolute_error: 1.4660\n",
            "Epoch 44/100\n"
          ]
        }
      ]
    }
  ]
}